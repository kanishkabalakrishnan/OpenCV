{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efeb8127-085c-41b9-8bfc-d09452e3e557",
   "metadata": {},
   "source": [
    "# Face Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c7a822-afa5-425d-8a41-8ad8e4d91122",
   "metadata": {},
   "source": [
    "### For Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ab2569-9206-410b-84ad-2c75dbe8b801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "#Trained Dataset\n",
    "train_dataset=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddae439f-5a3f-434c-af5b-037a6b2c319c",
   "metadata": {},
   "source": [
    "### Read a Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e61d2fc-7cdb-45d6-accf-6911ac49e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1=cv2.imread(r'C:\\Users\\gayat\\Downloads\\kani\\Face_Detection\\img1.png') #for single image\n",
    "cv2.imshow('single',img1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc707e4-0426-40ac-871d-b426fd4e4300",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2=cv2.imread('mul.jpg')#for multiple image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b151a0-b694-409f-aabc-6acd77fd81bc",
   "metadata": {},
   "source": [
    "### convert into grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a42cfb-cc72-489a-8fee-056d4ae3a6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert in to grayscale(for single image)\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "faces=train_dataset.detectMultiScale(gray)\n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887561e1-0642-40ee-873e-8f296ce076bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert in to grayscale(for multiple faces)\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "faces=train_dataset.detectMultiScale(gray)\n",
    "print(faces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02029523-ff8d-4816-8e1f-1d6fe04254f5",
   "metadata": {},
   "source": [
    "### for creating rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32bee05-01a4-45fc-bc9e-0241da9a3e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y,w,h in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    #cv2.rectangle(img,(x-axis,y-axis),(for create box),(255,0,0 for give color for box),2 for thickness)\n",
    "cv2.imshow('COLOR',img)\n",
    "cv2.imshow('GRAY',gray)\n",
    "\n",
    "cv2.waitKey()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97c62fe-8075-4bbe-85ed-2dc796b6ecbe",
   "metadata": {},
   "source": [
    "# For video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b409367-4b55-46d7-806b-8c396bbd00e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "#Trained Dataset\n",
    "train_dataset=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "video=cv2.VideoCapture('v_single.mp4')\n",
    "# for loop capturing(if we don't give that loop we have press any key to move the video )\n",
    "while True:\n",
    "   success,frame=video.read()\n",
    "   if success==True:\n",
    "      gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "      faces=train_dataset.detectMultiScale(gray)\n",
    "      for x,y,w,h in faces:\n",
    "         cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "         #cv2.rectangle(img,(x-axis,y-axis),(for create box),(255,0,0 for give color for box),2 for thickness)\n",
    "      cv2.imshow('video',frame)\n",
    "      cv2.waitKey(1)  \n",
    "   else:\n",
    "      print(\"video completed ot frame nil\")\n",
    "      break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da51268-3e78-4cb2-90a0-1b1cfa9c28ad",
   "metadata": {},
   "source": [
    "# For Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bb4e87-fc63-41cd-a700-5409590bf286",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "#Trained Dataset\n",
    "train_dataset=cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "video=cv2.VideoCapture(0)#capturevideo from our webcam\n",
    "while True:\n",
    "   success,frame=video.read()\n",
    "   if success==True:\n",
    "      gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "      faces=train_dataset.detectMultiScale(gray)\n",
    "      for x,y,w,h in faces:\n",
    "         cv2.rectangle(frame,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "         #cv2.rectangle(img,(x-axis,y-axis),(for create box),(255,0,0 for give color for box),2 for thickness)\n",
    "      cv2.imshow('video',frame)\n",
    "      key=cv2.waitKey(1)  \n",
    "      if key==81 or key==113:\n",
    "         break\n",
    "   else:\n",
    "      print(\"video completed ot frame nil\")\n",
    "      break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
